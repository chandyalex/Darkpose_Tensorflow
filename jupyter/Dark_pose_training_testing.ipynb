{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d084ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('/home/chandy/gsoc/Darkpose_Tensorflow/lib/')\n",
    "import tensorflow as tf\n",
    "# from tensorflow.python.framework.ops import disable_eager_execution\n",
    "# disable_eager_execution()\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# logging.debug(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7fb4c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import coco\n",
    "from data import coco_data\n",
    "from config import cfg\n",
    "from core.loss import JointsMSELoss,JointsOHKMMSELoss,dice_loss\n",
    "from models import pose_resnet\n",
    "from core.evaluation import accuracy\n",
    "\n",
    "from core.dark_function import train,validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4da3f49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.77s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.89s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "optimizer=tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "data_gen = coco.COCODataset(cfg, cfg.DATASET.ROOT, cfg.DATASET.TRAIN_SET, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4700a545",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model= pose_resnet.get_pose_net(\n",
    "        cfg, is_train=True\n",
    "    )\n",
    "model.build(input_shape=(None,256, 256, 3))\n",
    "\n",
    "model.compile(loss=JointsMSELoss, optimizer='SGD',run_eagerly=True)\n",
    "# model.summary()\n",
    "# model.fit(data_gen,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc745a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pose_res_net\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              multiple                  9472      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo multiple                  256       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 multiple                  0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) multiple                  0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 64, 64, 256)       218624    \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 32, 32, 512)       1226752   \n",
      "_________________________________________________________________\n",
      "sequential_5 (Sequential)    (None, 16, 16, 1024)      7118848   \n",
      "_________________________________________________________________\n",
      "sequential_7 (Sequential)    (None, 8, 8, 2048)        14987264  \n",
      "_________________________________________________________________\n",
      "sequential_8 (Sequential)    (None, 64, 64, 256)       10488832  \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           multiple                  4369      \n",
      "=================================================================\n",
      "Total params: 34,054,417\n",
      "Trainable params: 33,954,321\n",
      "Non-trainable params: 100,096\n",
      "_________________________________________________________________\n",
      "Training loss (for one batch) at step 0: 0.0006\n",
      "Seen so far: 64 samples\n",
      "Training loss (for one batch) at step 200: nan\n",
      "Seen so far: 12864 samples\n",
      "Training loss (for one batch) at step 400: nan\n",
      "Seen so far: 25664 samples\n",
      "Training loss (for one batch) at step 600: nan\n",
      "Seen so far: 38464 samples\n",
      "Training loss (for one batch) at step 800: nan\n",
      "Seen so far: 51264 samples\n",
      "Training loss (for one batch) at step 1000: nan\n",
      "Seen so far: 64064 samples\n",
      "Training loss (for one batch) at step 1200: nan\n",
      "Seen so far: 76864 samples\n",
      "Training loss (for one batch) at step 1400: nan\n",
      "Seen so far: 89664 samples\n",
      "Training loss (for one batch) at step 1600: nan\n",
      "Seen so far: 102464 samples\n",
      "Training loss (for one batch) at step 1800: nan\n",
      "Seen so far: 115264 samples\n",
      "Training loss (for one batch) at step 2000: nan\n",
      "Seen so far: 128064 samples\n",
      "Training loss (for one batch) at step 2200: nan\n",
      "Seen so far: 140864 samples\n",
      "Training loss (for one batch) at step 2400: nan\n",
      "Seen so far: 153664 samples\n",
      "Training loss (for one batch) at step 2600: nan\n",
      "Seen so far: 166464 samples\n",
      "Training loss (for one batch) at step 2800: nan\n",
      "Seen so far: 179264 samples\n",
      "Training loss (for one batch) at step 3000: nan\n",
      "Seen so far: 192064 samples\n",
      "Training loss (for one batch) at step 3200: nan\n",
      "Seen so far: 204864 samples\n",
      "Training loss (for one batch) at step 3400: nan\n",
      "Seen so far: 217664 samples\n",
      "Training loss (for one batch) at step 3600: nan\n",
      "Seen so far: 230464 samples\n",
      "Training loss (for one batch) at step 3800: nan\n",
      "Seen so far: 243264 samples\n",
      "Training loss (for one batch) at step 4000: nan\n",
      "Seen so far: 256064 samples\n",
      "Training loss (for one batch) at step 4200: nan\n",
      "Seen so far: 268864 samples\n",
      "Training loss (for one batch) at step 4400: nan\n",
      "Seen so far: 281664 samples\n",
      "Training loss (for one batch) at step 4600: nan\n",
      "Seen so far: 294464 samples\n",
      "Training loss (for one batch) at step 4800: nan\n",
      "Seen so far: 307264 samples\n",
      "Training loss (for one batch) at step 5000: nan\n",
      "Seen so far: 320064 samples\n",
      "Training loss (for one batch) at step 5200: nan\n",
      "Seen so far: 332864 samples\n",
      "Training loss (for one batch) at step 5400: nan\n",
      "Seen so far: 345664 samples\n",
      "Training loss (for one batch) at step 5600: nan\n",
      "Seen so far: 358464 samples\n",
      "Training loss (for one batch) at step 5800: nan\n",
      "Seen so far: 371264 samples\n",
      "Training loss (for one batch) at step 6000: nan\n",
      "Seen so far: 384064 samples\n",
      "Training loss (for one batch) at step 6200: nan\n",
      "Seen so far: 396864 samples\n",
      "Training loss (for one batch) at step 6400: nan\n",
      "Seen so far: 409664 samples\n",
      "Training loss (for one batch) at step 6600: nan\n",
      "Seen so far: 422464 samples\n",
      "Training loss (for one batch) at step 6800: nan\n",
      "Seen so far: 435264 samples\n",
      "Training loss (for one batch) at step 7000: nan\n",
      "Seen so far: 448064 samples\n",
      "Training loss (for one batch) at step 7200: nan\n",
      "Seen so far: 460864 samples\n",
      "Training loss (for one batch) at step 7400: nan\n",
      "Seen so far: 473664 samples\n",
      "Training loss (for one batch) at step 7600: nan\n",
      "Seen so far: 486464 samples\n",
      "Training loss (for one batch) at step 7800: nan\n",
      "Seen so far: 499264 samples\n",
      "Training loss (for one batch) at step 8000: nan\n",
      "Seen so far: 512064 samples\n",
      "Training loss (for one batch) at step 8200: nan\n",
      "Seen so far: 524864 samples\n",
      "Training loss (for one batch) at step 8400: nan\n",
      "Seen so far: 537664 samples\n",
      "Training loss (for one batch) at step 8600: nan\n",
      "Seen so far: 550464 samples\n",
      "Training loss (for one batch) at step 8800: nan\n",
      "Seen so far: 563264 samples\n",
      "Training loss (for one batch) at step 9000: nan\n",
      "Seen so far: 576064 samples\n",
      "Training loss (for one batch) at step 9200: nan\n",
      "Seen so far: 588864 samples\n",
      "Training loss (for one batch) at step 9400: nan\n",
      "Seen so far: 601664 samples\n",
      "Training loss (for one batch) at step 9600: nan\n",
      "Seen so far: 614464 samples\n",
      "Training loss (for one batch) at step 9800: nan\n",
      "Seen so far: 627264 samples\n",
      "Training loss (for one batch) at step 10000: nan\n",
      "Seen so far: 640064 samples\n",
      "Training loss (for one batch) at step 10200: nan\n",
      "Seen so far: 652864 samples\n",
      "Training loss (for one batch) at step 10400: nan\n",
      "Seen so far: 665664 samples\n",
      "Training loss (for one batch) at step 10600: nan\n",
      "Seen so far: 678464 samples\n",
      "Training loss (for one batch) at step 10800: nan\n",
      "Seen so far: 691264 samples\n",
      "Training loss (for one batch) at step 11000: nan\n",
      "Seen so far: 704064 samples\n",
      "Training loss (for one batch) at step 11200: nan\n",
      "Seen so far: 716864 samples\n",
      "Training loss (for one batch) at step 11400: nan\n",
      "Seen so far: 729664 samples\n",
      "Training loss (for one batch) at step 11600: nan\n",
      "Seen so far: 742464 samples\n",
      "Training loss (for one batch) at step 11800: nan\n",
      "Seen so far: 755264 samples\n",
      "Training loss (for one batch) at step 12000: nan\n",
      "Seen so far: 768064 samples\n",
      "Training loss (for one batch) at step 12200: nan\n",
      "Seen so far: 780864 samples\n",
      "Training loss (for one batch) at step 12400: nan\n",
      "Seen so far: 793664 samples\n",
      "Training loss (for one batch) at step 12600: nan\n",
      "Seen so far: 806464 samples\n",
      "Training loss (for one batch) at step 12800: nan\n",
      "Seen so far: 819264 samples\n",
      "Training loss (for one batch) at step 13000: nan\n",
      "Seen so far: 832064 samples\n",
      "Training loss (for one batch) at step 13200: nan\n",
      "Seen so far: 844864 samples\n",
      "Training loss (for one batch) at step 13400: nan\n",
      "Seen so far: 857664 samples\n",
      "Training loss (for one batch) at step 13600: nan\n",
      "Seen so far: 870464 samples\n",
      "Training loss (for one batch) at step 13800: nan\n",
      "Seen so far: 883264 samples\n",
      "Training loss (for one batch) at step 14000: nan\n",
      "Seen so far: 896064 samples\n",
      "Training loss (for one batch) at step 14200: nan\n",
      "Seen so far: 908864 samples\n",
      "Training loss (for one batch) at step 14400: nan\n",
      "Seen so far: 921664 samples\n",
      "Training loss (for one batch) at step 14600: nan\n",
      "Seen so far: 934464 samples\n"
     ]
    }
   ],
   "source": [
    "epoch=2\n",
    "for i in range(epoch):\n",
    "    train(cfg,data_gen,model,JointsMSELoss,optimizer,i)\n",
    "    validate(cfg,data_gen,model,JointsMSELoss)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7bc0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b9707d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4342e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90373c45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56930e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293a07ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0defc6da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f181f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0992dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
