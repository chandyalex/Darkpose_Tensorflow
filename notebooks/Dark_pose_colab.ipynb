{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dark_pose_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandyalex/GSoC-2021-TF-DarkPose/blob/main/notebooks/Dark_pose_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AcmWjMbg1YH"
      },
      "source": [
        "## About the colab notebook\n",
        "This colab notebook demonstrating how to integrate the new pose estimation model with DARK pose tensorflow  library, \n",
        "- Since coco datset is large we choose the cpu colab for this demonsration.( GPU colab has not enough disk space to accomodate the entire data)\n",
        "- The TPU support is still under development, final version of the library which handle all kind of hardware will be realease as the part of post GSoC project goals."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb-ym87kHnR4"
      },
      "source": [
        "#### Step 1 \n",
        " - Making directory and downloading coco data set in zip format.\n",
        " - Unzipping downloded files .\n",
        " - Removing the zip file aftre extraction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfDh9jZsvW1y"
      },
      "source": [
        "# making directory and downloading data in to the disk\n",
        "! mkdir -p /content/data/coco/images/\n",
        "! wget http://images.cocodataset.org/zips/train2017.zip -P /content/data/coco/images\n",
        "! wget http://images.cocodataset.org/zips/val2017.zip -P /content/data/coco/images\n",
        "! wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip -P /content/data/coco\n",
        "! unzip /content/data/coco/images/train2017.zip -d /content/data/coco/images\n",
        "! unzip /content/data/coco/images/val2017.zip -d /content/data/coco/images\n",
        "! unzip /content/data/coco/annotations_trainval2017.zip -d /content/data/coco/\n",
        "! rm -r /content/data/coco/images/val2017.zip\n",
        "! rm -r /content/data/coco/images/train2017.zip\n",
        "! rm -r /content/data/coco/annotations_trainval2017.zip\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8q0FuVkICc1"
      },
      "source": [
        "#### Step 2\n",
        "Installing all the dependencied for the library\n",
        "- Cloning COCO API from git and installing\n",
        "- Cloning Dark Pose Tensorflow repository and installing dependencies mentioned in 'requirements.txt'\n",
        "- Building 'nms' library using make command inside the repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gbHWCeKHi5Q"
      },
      "source": [
        "# installing dependencies \n",
        "\n",
        "! git clone https://github.com/cocodataset/cocoapi.git\n",
        "! git clone https://github.com/chandyalex/GSoC-2021-TF-DarkPose.git\n",
        "! python /content/cocoapi/PythonAPI/setup.py install\n",
        "! pip install -r /content/GSoC-2021-TF-DarkPose/requirements.txt\n",
        "# building nms library\n",
        "! cd /content/GSoC-2021-TF-DarkPose/  &&\\make"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mu6FqbVlKcnQ"
      },
      "source": [
        "#### Step 3\n",
        "Importing all necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAxNQqNy0yPh"
      },
      "source": [
        "# importing essential libraries\n",
        "import sys\n",
        "sys.path.append('/content/GSoC-2021-TF-DarkPose')\n",
        "import tensorflow as tf\n",
        "from models import pose_resnet\n",
        "from utils.utils import get_optimizer\n",
        "\n",
        "from data import coco\n",
        "from data import coco_data\n",
        "from config import cfg\n",
        "from config import update_config\n",
        "from core.evaluation import accuracy\n",
        "from core.dark_function import train,validate\n",
        "from core.loss import JointsMSELoss,JointsOHKMMSELoss,dice_loss\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB6VfQGLKjeU"
      },
      "source": [
        "#### Step 4\n",
        "Setting up all the data directory and related pameters inside the config file.\n",
        "Feel free to edit the config file in /experiments folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw7vVMtPfvgQ"
      },
      "source": [
        "# setting the data directory in to config\n",
        "cfg.DATA_DIR=\"/content/data/coco/\"\n",
        "cfg.OUTPUT_DIR='out/'\n",
        "cfg.LOG_DIR='log/'\n",
        "cfg.DATASET.ROOT=\"/content/data/coco/\"\n",
        "cfg.DATASET.TEST_SET=\"val2017\"\n",
        "cfg.DATASET.TRAIN_SET=\"train2017\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNVeSo4UK2Ab"
      },
      "source": [
        "#### Step 5\n",
        "Loading training and validation dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCuXWO5S027M",
        "outputId": "4751629c-03cd-4d13-c09a-71258d35531f"
      },
      "source": [
        "# data loader\n",
        "train_data = coco.COCODataset(cfg, cfg.DATASET.ROOT, cfg.DATASET.TRAIN_SET, True)\n",
        "valid_dataset = coco.COCODataset(cfg, cfg.DATASET.ROOT, cfg.DATASET.TEST_SET, False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=8.52s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=10.40s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=0.26s)\n",
            "creating index...\n",
            "index created!\n",
            "loading annotations into memory...\n",
            "Done (t=1.46s)\n",
            "creating index...\n",
            "index created!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FM7-JlRZIx2S"
      },
      "source": [
        "#### Step 6\n",
        "At this point the pose estimation model can be initialized and build using input shape of data loader, in this colab we are using posresnet(baseline) model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVeDygc-06gE",
        "outputId": "5c7e8d77-86b7-4a01-8ce7-8f6d93ac553b"
      },
      "source": [
        "# building model\n",
        "model= pose_resnet.get_pose_net(\n",
        "        cfg, is_train=True\n",
        "    )\n",
        "\n",
        "optimizer = get_optimizer(cfg, model)\n",
        "\n",
        "model.build(input_shape=train_data[0][0].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASGDVArqJIGV"
      },
      "source": [
        "#### Step 7\n",
        "While training make sure that the train and validate function from 'core.dark_function'  library is used. The initilized model will be passed to the train function and estimation of heat map using DARK pose method will be takenplace inside these function. For detailed understating check the train.py script in the main repository."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2X4XAfFE07sd",
        "outputId": "793f3653-cfa8-428b-f99c-6e21e0f1f05a"
      },
      "source": [
        "# training\n",
        "epoch=1\n",
        "for i in range(epoch):\n",
        "      train(cfg,train_data,model,JointsMSELoss,optimizer,i)\n",
        "      validate(cfg,valid_dataset,model,JointsMSELoss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"pose_res_net\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              multiple                  9472      \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo multiple                  256       \n",
            "_________________________________________________________________\n",
            "re_lu (ReLU)                 multiple                  0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) multiple                  0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (32, 32, 24, 256)         218624    \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (32, 16, 12, 512)         1226752   \n",
            "_________________________________________________________________\n",
            "sequential_5 (Sequential)    (32, 8, 6, 1024)          7118848   \n",
            "_________________________________________________________________\n",
            "sequential_7 (Sequential)    (32, 4, 3, 2048)          14987264  \n",
            "_________________________________________________________________\n",
            "sequential_8 (Sequential)    (32, 32, 24, 256)         10488832  \n",
            "_________________________________________________________________\n",
            "conv2d_53 (Conv2D)           multiple                  4369      \n",
            "=================================================================\n",
            "Total params: 34,054,417\n",
            "Trainable params: 33,954,321\n",
            "Non-trainable params: 100,096\n",
            "_________________________________________________________________\n",
            "Epoch: [0][0/3696]\tTime 12.005s (12.005s)\tSpeed 2.7 samples/s\tData 0.254s (0.254s)\tLoss 0.00245 (0.00245)\tAccuracy 0.643 (0.643)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}